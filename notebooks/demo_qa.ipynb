{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9de27de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "# Configure logging to show in console\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(),  # This outputs to console\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Reload modules automatically when they change\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24940a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/linafaik/Documents/projects/agentic-investor-brief\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d683fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-03 21:11:15,037 - root - INFO - Environment setup completed\n",
      "2025-10-03 21:11:15,037 - root - INFO - MLflow tracking: sqlite:///mlflow.db\n",
      "2025-10-03 21:11:15,038 - root - INFO - Default model: gpt-5-nano\n",
      "2025-10-03 21:11:15,038 - root - INFO - Output directory: outputs\n"
     ]
    }
   ],
   "source": [
    "from agent_investor_brief.config import setup_environment\n",
    "from agent_investor_brief.agents.investor_agent import InvestorAgent\n",
    "from agent_investor_brief.agents.qa_agent import CompanyQAAgent\n",
    "from agent_investor_brief.tools.industry_research import IndustryResearchTool\n",
    "from agent_investor_brief.tools.financial_data import FinancialDataTool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6976d38c",
   "metadata": {},
   "source": [
    "### QA Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4cef616",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/03 21:11:17 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2025/10/03 21:11:17 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test 1: AAPL\n",
      "Question: What's Apple's current stock price?\n",
      "Success: True\n",
      "Tools used: ['financial']\n",
      "Answer preview: Apple (AAPL) is trading at $258.16, up 0.40% on the day. Last updated: 2025-10-03 21:11 UTC.\n",
      "✓ Passed\n",
      "\n",
      "Test 2: TSLA\n",
      "Question: How is Tesla positioned in the electric vehicle market?\n",
      "Success: True\n",
      "Tools used: ['financial', 'industry']\n",
      "Answer preview: Short answer: Tesla remains the EV market’s scale and brand leader, but its dominance is narrowing as competition intensifies and margins compress.\n",
      "\n",
      "Position today\n",
      "- Market leadership (U.S.): Estimated 43.1% EV market share through September 2025, down from ~49% at the end of last year, as more rival models launch. U.S. EVs reached ~10.5% of auto sales in Q3, indicating a growing but more competitive market.\n",
      "- Global scale: Deliveries were about 1.79 million in 2024 (Morningstar), putting Tesla among the top global EV makers; competition is fiercest in China from players like BYD, XPeng, and NIO.\n",
      "- Financial strength and pressure: 2024 revenue was $97.7B (roughly flat vs. 2023), with net income of $7.1B and a 6.3% net margin; operating margin was 4.1%. Price cuts and mix shifts have compressed margins versus prior years. Liquidity remains solid (cash and equivalents ~$16.1B; current ratio ~2.0).\n",
      "- Technology and ecosystem: Tesla benefits from vertical integration, software (including FSD), and a large fast‑charging network, which support customer lock‑in and cost advantages.\n",
      "\n",
      "Outlook and debates\n",
      "- Growth trajectory: Management has talked up 20%–30% deliveries growth for 2025, but some analysts expect slower growth or even a decline (Morningstar forecasts ~1.65M deliveries in 2025, down from 2024) as the “affordable” model takes time to ramp and robotaxi timelines remain uncertain.\n",
      "- Valuation vs. fundamentals: Shares are up ~77% YTD with a high P/E (~251) and a consensus Hold rating; the average analyst target (~$347) implies downside from the current price (~$426), suggesting expectations are elevated relative to near‑term earnings growth.\n",
      "- Competitive dynamics: Legacy automakers (GM, Ford, VW, Hyundai/Kia) and Chinese EV makers (notably BYD) are eroding share via broader lineups and price competition, particularly in China.\n",
      "\n",
      "Bottom line\n",
      "- Tesla is still the benchmark EV brand with unmatched scale in the U.S., strong global presence, and a powerful technology/charging ecosystem. However, its market share is slipping as the category matures, and 2024 showed slower top‑line growth with margin compression. Near‑term execution on the affordable vehicle and any tangible progress in autonomy are key catalysts; persistent price competition and China exposure are the main risks.\n",
      "✓ Passed\n",
      "\n",
      "Test 3: MSFT\n",
      "Question: What are Microsoft's revenue and profit margins?\n",
      "Success: True\n",
      "Tools used: ['financial']\n",
      "Answer preview: Here are Microsoft’s latest annual figures:\n",
      "\n",
      "- Revenue: $281.7 billion\n",
      "- Gross margin: ~68.8% (gross profit $193.9B / revenue $281.7B)\n",
      "- Operating margin: 44.9%\n",
      "- Net profit margin: 36.1% (net income $101.8B / revenue $281.7B)\n",
      "\n",
      "Source: Latest fiscal year data.\n",
      "✓ Passed\n",
      "\n",
      "Test 4: GOOGL\n",
      "Question: What are Google's main business segments?\n",
      "Success: True\n",
      "Tools used: ['financial', 'industry']\n",
      "Answer preview: Alphabet (GOOGL) reports three main business segments:\n",
      "\n",
      "- Google Services: Consumer products and ads, including Search, YouTube, Google Ads, Android, Chrome, Gmail, Drive, Maps, Photos, Google Play (apps and in‑app purchases), devices (hardware), and subscription services. This is the company’s largest revenue driver.\n",
      "- Google Cloud: Cloud infrastructure and platform services (AI infrastructure, Vertex AI, data/analytics, cybersecurity) plus Google Workspace (Gmail, Docs, Drive, Meet) for enterprises.\n",
      "- Other Bets: Early‑stage businesses that sell healthcare‑related and internet services.\n",
      "\n",
      "For context, Alphabet’s latest annual results show $350.0B in revenue and $100.1B in net income (tool data), with Services contributing the majority of revenue.\n",
      "✓ Passed\n"
     ]
    }
   ],
   "source": [
    "agent = CompanyQAAgent(model_name=\"gpt-5\")\n",
    "\n",
    "test_cases = [\n",
    "    {\n",
    "        \"company\": \"AAPL\",\n",
    "        \"question\": \"What's Apple's current stock price?\",\n",
    "        \"expected_tool\": \"financial\"\n",
    "    },\n",
    "    {\n",
    "        \"company\": \"TSLA\", \n",
    "        \"question\": \"How is Tesla positioned in the electric vehicle market?\",\n",
    "        \"expected_tool\": \"industry\"\n",
    "    },\n",
    "    {\n",
    "        \"company\": \"MSFT\",\n",
    "        \"question\": \"What are Microsoft's revenue and profit margins?\",\n",
    "        \"expected_tool\": \"financial\"\n",
    "    },\n",
    "    {\n",
    "        \"company\": \"GOOGL\",\n",
    "        \"question\": \"What are Google's main business segments?\",\n",
    "        \"expected_tool\": \"industry\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for i, test_case in enumerate(test_cases, 1):\n",
    "    print(f\"\\nTest {i}: {test_case['company']}\")\n",
    "    print(f\"Question: {test_case['question']}\")\n",
    "    \n",
    "    result = agent.ask_question(test_case['question'], test_case['company'])\n",
    "    \n",
    "    print(f\"Success: {result['success']}\")\n",
    "    print(f\"Tools used: {result.get('tools_used', [])}\")\n",
    "    print(f\"Answer preview: {result['answer']}\")\n",
    "    \n",
    "    # Basic validation\n",
    "    assert result['success'], f\"Test {i} failed\"\n",
    "    assert len(result['answer']) > 10, f\"Test {i} has very short answer\"\n",
    "    \n",
    "    print(\"✓ Passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfcd57c",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0491130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mlflow\n",
    "from mlflow.genai import scorer\n",
    "from mlflow.genai.scorers import Correctness, Guidelines\n",
    "\n",
    "# Questions list\n",
    "evaluation_questions = [\n",
    "    {\n",
    "        \"ticker\": \"AAPL\",\n",
    "        \"question\": \"What is Apple's current P/E ratio and how does it compare to the tech sector average?\",\n",
    "        \"expected_tool\": \"financial\"\n",
    "    },\n",
    "    {\n",
    "        \"ticker\": \"TSLA\", \n",
    "        \"question\": \"What is Tesla's market share in the global electric vehicle market and who are its main competitors?\",\n",
    "        \"expected_tool\": \"industry\"\n",
    "    },\n",
    "    {\n",
    "        \"ticker\": \"MSFT\",\n",
    "        \"question\": \"What are Microsoft's quarterly revenue growth rates for the past 4 quarters?\",\n",
    "        \"expected_tool\": \"financial\"\n",
    "    },\n",
    "    {\n",
    "        \"ticker\": \"NVDA\",\n",
    "        \"question\": \"What are NVIDIA's gross margins and how have they changed due to AI demand?\",\n",
    "        \"expected_tool\": \"financial\"\n",
    "    },\n",
    "    {\n",
    "        \"ticker\": \"AMZN\",\n",
    "        \"question\": \"What are Amazon's main revenue streams and which segment generates the highest profit margins?\",\n",
    "        \"expected_tool\": \"industry\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Step 1: Generate ground truth answers \n",
    "def generate_ground_truth(model_name=\"gpt-5\"):\n",
    "    agent = CompanyQAAgent(model_name=model_name)\n",
    "    ground_truth = []\n",
    "    \n",
    "    for q in evaluation_questions:\n",
    "        result = agent.ask_question(q[\"question\"], q[\"ticker\"])\n",
    "        ground_truth.append({\n",
    "            \"ticker\": q[\"ticker\"],\n",
    "            \"question\": q[\"question\"],\n",
    "            \"ground_truth\": result[\"answer\"]\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(ground_truth)\n",
    "\n",
    "@scorer\n",
    "def is_concise(outputs: str) -> bool:\n",
    "    \"\"\"Evaluate if the answer is concise \"\"\"\n",
    "    return len(outputs.split()) <= 500 and len(outputs.split()) >= 100\n",
    "\n",
    "# Step 3: Define scorers\n",
    "scorers = [\n",
    "    Correctness(),\n",
    "    is_concise,\n",
    "    Guidelines(name=\"is_professional\", guidelines=\"The answer tone must be in professional.\"),\n",
    "]\n",
    "\n",
    "# Step 4: Prediction function - simplified to match MLflow's expectations\n",
    "def qa_predict_fn(inputs, current_model):\n",
    "    \"\"\"\n",
    "    MLflow passes 'inputs' and any other keys from the 'inputs' dict as separate arguments\n",
    "    \n",
    "    Args:\n",
    "        inputs: The question and ticker combined string\n",
    "        current_model: The model name to use\n",
    "    \"\"\"\n",
    "    # Parse the input string to extract question and ticker\n",
    "    # Assuming format: \"question Ticker : ticker_symbol\"\n",
    "    parts = inputs.split(\" Ticker : \")\n",
    "    question = parts[0]\n",
    "    ticker = parts[1] if len(parts) > 1 else \"\"\n",
    "    \n",
    "    agent = CompanyQAAgent(model_name=current_model)\n",
    "    result = agent.ask_question(question, ticker)\n",
    "    \n",
    "    return result[\"answer\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c735a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating ground truth...\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating ground truth...\")\n",
    "ground_truth_df = generate_ground_truth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93d8c513",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/03 21:18:57 INFO mlflow.models.evaluation.utils.trace: Auto tracing is temporarily enabled during the model evaluation for computing some metrics and debugging. To disable tracing, call `mlflow.autolog(disable=True)`.\n",
      "2025/10/03 21:18:57 INFO mlflow.genai.utils.data_validation: Testing model prediction with the first sample in the dataset.\n",
      "ERROR [root] Error in ask_question: Run with UUID c2bdc64f95254e389b9064ef0a56d357 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating gpt-5-nano...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da36555a65e84b0da857d5036596e378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/5 [Elapsed: 00:00, Remaining: ?] "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/03 21:19:25 ERROR mlflow.genai.scorers.aggregation: Invalid assessment value for is_professional: None\n",
      "2025/10/03 21:19:25 ERROR mlflow.genai.scorers.aggregation: Invalid assessment value for correctness: None\n",
      "2025/10/03 21:19:25 ERROR mlflow.genai.scorers.aggregation: Invalid assessment value for correctness: None\n",
      "2025/10/03 21:19:25 ERROR mlflow.genai.scorers.aggregation: Invalid assessment value for is_professional: None\n",
      "2025/10/03 21:19:25 ERROR mlflow.genai.scorers.aggregation: Invalid assessment value for correctness: None\n",
      "2025/10/03 21:19:25 ERROR mlflow.genai.scorers.aggregation: Invalid assessment value for is_professional: None\n",
      "2025/10/03 21:19:25 ERROR mlflow.genai.scorers.aggregation: Invalid assessment value for correctness: None\n",
      "2025/10/03 21:19:25 ERROR mlflow.genai.scorers.aggregation: Invalid assessment value for is_professional: None\n",
      "2025/10/03 21:19:25 ERROR mlflow.genai.scorers.aggregation: Invalid assessment value for correctness: None\n",
      "2025/10/03 21:19:25 ERROR mlflow.genai.scorers.aggregation: Invalid assessment value for is_professional: None\n",
      "2025/10/03 21:19:25 INFO mlflow.genai.utils.data_validation: Testing model prediction with the first sample in the dataset.\n",
      "ERROR [root] Error in ask_question: Run with UUID 273ddd76f6a344ea9e7ddc4188b1aa27 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✨ Evaluation completed.\n",
      "\n",
      "Metrics and evaluation results are logged to the MLflow run:\n",
      "  Run name: \u001b[94mevaluation_gpt-5-nano\u001b[0m\n",
      "  Run ID: \u001b[94mc2bdc64f95254e389b9064ef0a56d357\u001b[0m\n",
      "\n",
      "To view the detailed evaluation results with sample-wise scores,\n",
      "open the \u001b[93m\u001b[1mTraces\u001b[0m tab in the Run page in the MLflow UI.\n",
      "\n",
      "Evaluation completed for gpt-5-nano\n",
      "Results: {'is_concise/mean': np.float64(0.8)}\n",
      "Evaluation completed for gpt-5-nano\n",
      "\n",
      "Evaluating gpt-5-mini...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa73e91dc6164293a3c5013051024f18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/5 [Elapsed: 00:00, Remaining: ?] "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/03 21:20:01 ERROR mlflow.genai.scorers.aggregation: Invalid assessment value for correctness: None\n",
      "2025/10/03 21:20:01 ERROR mlflow.genai.scorers.aggregation: Invalid assessment value for is_professional: None\n",
      "2025/10/03 21:20:01 ERROR mlflow.genai.scorers.aggregation: Invalid assessment value for correctness: None\n",
      "2025/10/03 21:20:01 ERROR mlflow.genai.scorers.aggregation: Invalid assessment value for is_professional: None\n",
      "2025/10/03 21:20:01 ERROR mlflow.genai.scorers.aggregation: Invalid assessment value for correctness: None\n",
      "2025/10/03 21:20:01 ERROR mlflow.genai.scorers.aggregation: Invalid assessment value for is_professional: None\n",
      "2025/10/03 21:20:01 ERROR mlflow.genai.scorers.aggregation: Invalid assessment value for correctness: None\n",
      "2025/10/03 21:20:01 ERROR mlflow.genai.scorers.aggregation: Invalid assessment value for is_professional: None\n",
      "2025/10/03 21:20:01 ERROR mlflow.genai.scorers.aggregation: Invalid assessment value for correctness: None\n",
      "2025/10/03 21:20:01 ERROR mlflow.genai.scorers.aggregation: Invalid assessment value for is_professional: None\n",
      "2025/10/03 21:20:01 INFO mlflow.genai.utils.data_validation: Testing model prediction with the first sample in the dataset.\n",
      "ERROR [root] Error in ask_question: Run with UUID 57a1068edc7c44fb8f86edf475170255 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✨ Evaluation completed.\n",
      "\n",
      "Metrics and evaluation results are logged to the MLflow run:\n",
      "  Run name: \u001b[94mevaluation_gpt-5-mini\u001b[0m\n",
      "  Run ID: \u001b[94m273ddd76f6a344ea9e7ddc4188b1aa27\u001b[0m\n",
      "\n",
      "To view the detailed evaluation results with sample-wise scores,\n",
      "open the \u001b[93m\u001b[1mTraces\u001b[0m tab in the Run page in the MLflow UI.\n",
      "\n",
      "Evaluation completed for gpt-5-mini\n",
      "Results: {'is_concise/mean': np.float64(0.4)}\n",
      "Evaluation completed for gpt-5-mini\n",
      "\n",
      "Evaluating gpt-4.1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16adb2df73f545f0b9fed4f2dafbf155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/5 [Elapsed: 00:00, Remaining: ?] "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/03 21:20:30 ERROR mlflow.genai.scorers.aggregation: Invalid assessment value for correctness: None\n",
      "2025/10/03 21:20:30 ERROR mlflow.genai.scorers.aggregation: Invalid assessment value for is_professional: None\n",
      "2025/10/03 21:20:30 ERROR mlflow.genai.scorers.aggregation: Invalid assessment value for correctness: None\n",
      "2025/10/03 21:20:30 ERROR mlflow.genai.scorers.aggregation: Invalid assessment value for is_professional: None\n",
      "2025/10/03 21:20:30 ERROR mlflow.genai.scorers.aggregation: Invalid assessment value for correctness: None\n",
      "2025/10/03 21:20:30 ERROR mlflow.genai.scorers.aggregation: Invalid assessment value for is_professional: None\n",
      "2025/10/03 21:20:30 ERROR mlflow.genai.scorers.aggregation: Invalid assessment value for correctness: None\n",
      "2025/10/03 21:20:30 ERROR mlflow.genai.scorers.aggregation: Invalid assessment value for is_professional: None\n",
      "2025/10/03 21:20:30 ERROR mlflow.genai.scorers.aggregation: Invalid assessment value for correctness: None\n",
      "2025/10/03 21:20:30 ERROR mlflow.genai.scorers.aggregation: Invalid assessment value for is_professional: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✨ Evaluation completed.\n",
      "\n",
      "Metrics and evaluation results are logged to the MLflow run:\n",
      "  Run name: \u001b[94mevaluation_gpt-4.1\u001b[0m\n",
      "  Run ID: \u001b[94m57a1068edc7c44fb8f86edf475170255\u001b[0m\n",
      "\n",
      "To view the detailed evaluation results with sample-wise scores,\n",
      "open the \u001b[93m\u001b[1mTraces\u001b[0m tab in the Run page in the MLflow UI.\n",
      "\n",
      "Evaluation completed for gpt-4.1\n",
      "Results: {'is_concise/mean': np.float64(0.8)}\n",
      "Evaluation completed for gpt-4.1\n"
     ]
    }
   ],
   "source": [
    "# Models to test\n",
    "models = [\"gpt-5-nano\", \"gpt-5-mini\", \"gpt-4.1\"]\n",
    "\n",
    "for model in models:\n",
    "    print(f\"\\nEvaluating {model}...\")\n",
    "    \n",
    "    # Prepare evaluation data\n",
    "\n",
    "    # Prepare evaluation data in MLflow's expected format\n",
    "    eval_data = []\n",
    "    for _, row in ground_truth_df.iterrows():\n",
    "        eval_data.append({\n",
    "            \"inputs\": {\n",
    "                \"inputs\": row[\"question\"]+\" Ticker : \"+row[\"ticker\"],\n",
    "                \"current_model\": model\n",
    "            },\n",
    "            \"expectations\": {\n",
    "                \"expected_response\": row[\"ground_truth\"]\n",
    "            },\n",
    "        })\n",
    "    \n",
    "    # Run evaluation\n",
    "    with mlflow.start_run(run_name=f\"evaluation_{model}\"):\n",
    "        results = mlflow.genai.evaluate(\n",
    "            data=eval_data,\n",
    "            predict_fn=qa_predict_fn,\n",
    "            scorers=scorers,\n",
    "        )\n",
    "        \n",
    "        print(f\"Evaluation completed for {model}\")\n",
    "        print(f\"Results: {results.metrics}\")\n",
    "    \n",
    "    print(f\"Evaluation completed for {model}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent-investor-brief",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
